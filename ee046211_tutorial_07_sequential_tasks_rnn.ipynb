{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nay-urmb14cC"
      },
      "source": [
        "# <img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/course-icon.png?raw=1\" style=\"height:50px;display:inline\"> EE 046211 - Technion - Deep Learning\n",
        "---\n",
        "\n",
        "#### Tal Daniel\n",
        "\n",
        "## Tutorial 07 - Sequential Tasks - Recurrent Neural Networks\n",
        "---\n",
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/rnn_1.jpg?raw=1\" style=\"height:200px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHtmFzbF14cW"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
        "---\n",
        "* [Natural Language Processing and Sequences](#-Natural-Language-Processing-and-Sequences)\n",
        "* [Text Preprocessing](#-Text-Preprocessing)\n",
        "* [Evaluation in NLP - Perplexity and BLEU](#-Evaluation-in-NLP---Perplexity-and-BLEU)\n",
        "* [Recurrent Neural Networks (RNNs)](#-Recurrent-Neural-Networks-(RNNs))\n",
        "* [Backpropagation Through Time (BPTT)](#-Backpropagation-Through-Time-(BPTT))\n",
        "* [Long Term Short Memory (LSTM)](#-Long-Term-Short-Memory-(LSTM))\n",
        "* [Gated Recurrent Unit (GRU)](#-Gated-Recurrent-Unit-(GRU))\n",
        "* [Attention](#-Attention)\n",
        "* [The Transformer](#-The-Transformer)\n",
        "* [Pretrained Models - BERT and GPT](#-Pretrained-Models---BERT-and-GPT)\n",
        "* [Recommended Videos](#-Recommended-Videos)\n",
        "* [Credits](#-Credits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "R9ejiBAF14cg"
      },
      "outputs": [],
      "source": [
        "# imports for the tutorial\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import torchtext.legacy.data as data\n",
        "import torchtext.legacy.datasets as datasets\n",
        "import torch.nn.functional as f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIlXDmge14cl"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/nolan/64/language.png\" style=\"height:50px;display:inline\"> Natural Language Processing and Sequences\n",
        "---\n",
        "* So far we have dealt with tabular data and images, but what about text or sequences?\n",
        "* Sequence modeling is the field of modeling sequences, e.g., text sentences, videos, stocks rate, trajectories in reinforcement learning or autonomous driving, wheather forecast and etc...\n",
        "* Unlike our previous assumption that the data we have is i.i.d., this is not usually the case in sequences (e.g., if you randomly change the words in a sentence, it would be very hard to understand its meaning).\n",
        "* We will focus on text data in the field of natural language processing (NLP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gyNCSo614cn"
      },
      "source": [
        "#### Language Models\n",
        "---\n",
        "* Language models assign a probability to a text: $p(x_0, \\cdots, x_n)$\n",
        "* The most popular method is to factorize distribution using the basic probability principles and the Markovian assumption: $$p(x_0, \\cdots, x_n) = p(x_0)p(x_1|x_0)\\cdots p(x_n|x_{n-1})$$\n",
        "* However, this approach makes many assumptions that are unecessarily true (e.g. Markovian assumption -  dependency only on the previous word and not the entire history). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiCPDl0t14co"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/lang_model.gif?raw=1\" style=\"height:250px\">\n",
        "\n",
        "* <a href=\"https://medium.com/perceptronai/recurrent-neural-network-an-introduction-for-beginners-1c13a541c906\">Image Source</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HJZ8cnj14cs"
      },
      "source": [
        "#### Neural Language Models\n",
        "---\n",
        "* There are classical ways to build a language models, but the focus of this course is deep learning, so we will leave the classical approaches to the various NLP courses.\n",
        "* **Embeddings**: Basically we input the text into a neural network, the neural network will map all this context onto a vector. This vector represents the next word and we have some big word embedding matrix. The word embedding matrix contains a vector for every possible word the model can output.\n",
        "* The first neural language models were convolutional-based (1D):\n",
        "    * Embed each word as a vector, which is a lookup table to the embedding matrix, so the word will get the same vector no matter what context it appears in.\n",
        "    * Apply same feed forward network at each time step.\n",
        "    * Unfortunately, fixed length history means it can only condition on bounded context, but these models are very fast!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3PpQays14cw"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/lang_model_conv.jpg?raw=1\" style=\"height:300px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMONnPpH14cy"
      },
      "source": [
        "#### Forms of Sequence Prediction Tasks\n",
        "---\n",
        "* **One-to-one**: from fixed-sized input to fixed-sized output (e.g. image classification).\n",
        "* **One-to-many**: Sequence output (e.g. image captioning takes an image and outputs a sentence of words).\n",
        "* **Many-to-one**: Sequence input (e.g. sentiment analysis where a given sentence is classified as expressing positive or negative sentiment or given some text predict the next character)\n",
        "* **Many-to-many**: Sequence input and sequence output (e.g. Machine Translation).\n",
        "* **Many-to-many**: Synced sequence input and output (e.g. video classification where we wish to label each frame of the video)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkXx_GQv14c0"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/seq_tasks.jpeg?raw=1\" style=\"height:250px\">\n",
        "\n",
        "* <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">Image Source</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUmNNEQY14c2"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/bubbles/50/000000/connection-sync.png\" style=\"height:50px;display:inline\"> Text Preprocessing\n",
        "---\n",
        "* Before we dive into the specific models, we need to understand how to process text data, as you can't just feed words to neural networks, but you need to give them some numerical representation.\n",
        "    * In classic NLP, the words are sometimes represented as one-hot vectors, where the vector's size is the vocabulary size.\n",
        "* The general steps are:\n",
        "    * Load text as strings into memory.\n",
        "    * **Tokenization**: Split strings into tokens (e.g., words, parts of words and characters).\n",
        "    * **Vocabulary**: Build a table of vocabulary to map the split tokens to numerical indices.\n",
        "    * Convert text into sequences of numerical indices so they can be manipulated by models easily.\n",
        "* We will use `torchtext`, the official PyTorch library to handle text data.\n",
        "* We use the IMDB dataset: this dataset contains movie reviews which are labeled as `positive` and `negative` (for good and bad reviews, respectively).\n",
        "    * This task is called **sentiment analysis** in NLP, and it is essentially a classification task.\n",
        "* If you want to load other datasets or load a custom dataset: https://torchtext.readthedocs.io/en/latest/datasets.html\n",
        "* **Special tokens**:\n",
        "    * `<sos>` - token that marks the start of a sentence.\n",
        "    * `<pad>` - token that is used to pad sentences that are shorter than the longest sentence in a batch.\n",
        "    * `<eos>` - token that marks the end of a sentence.\n",
        "    * `<unk>` - token that marks unknown words (e.g., if the model thinks that no word in the vocabulary is good as next word or you decided to leave out some words, like names)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "qYqrrGyF14c3",
        "outputId": "4379440a-24e5-4e05-8cf4-d8ff5d48fc54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  25000\n",
            "test :  25000\n",
            "train.fields : {'text': <torchtext.legacy.data.field.Field object at 0x7f8ae7062bd0>, 'label': <torchtext.legacy.data.field.LabelField object at 0x7f8ae7062c50>}\n"
          ]
        }
      ],
      "source": [
        "max_len = 200  # max length of a sequence\n",
        "# define a text field\n",
        "text = data.Field(sequential=True, fix_length=max_len, batch_first=True, lower=True, dtype=torch.long)\n",
        "# define a label field\n",
        "label = data.LabelField(sequential=False, dtype=torch.long)\n",
        "# uncomment the following to download the imdb dataset\n",
        "datasets.IMDB.download('./datasets')\n",
        "# split to train and test\n",
        "ds_train, ds_test = datasets.IMDB.splits(text, label, path='./datasets/imdb/aclImdb/')\n",
        "# if you want to load a custom text dataset, you can take a look at how `datasets.IMDB` is implemented\n",
        "print('train : ', len(ds_train))\n",
        "print('test : ', len(ds_test))\n",
        "print('train.fields :', ds_train.fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "76Eoa8o-14dA",
        "outputId": "308864df-b375-41f6-887c-2743c014adff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train :  22500\n",
            "valid :  2500\n",
            "test :  25000\n"
          ]
        }
      ],
      "source": [
        "# further split to train and validation\n",
        "ds_train, ds_valid = ds_train.split(0.9)\n",
        "print('train : ', len(ds_train))\n",
        "print('valid : ', len(ds_valid))\n",
        "print('test : ', len(ds_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "m4TB6-c614dC"
      },
      "outputs": [],
      "source": [
        "# build a vocabulary\n",
        "num_words = 50_000  # a fancy way to write 50,000\n",
        "text.build_vocab(ds_train, max_size=num_words)  # sorted by frequency, take top-`num_words`\n",
        "label.build_vocab(ds_train)\n",
        "vocab = text.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bDDMH6Dy14dD",
        "outputId": "55587163-234f-46ac-c8dc-f6759445916a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the token of 'what': 48\n",
            "token number 27 is: he\n",
            "special tokens:\n",
            "<pad>:  1\n",
            "<unk>:  0\n"
          ]
        }
      ],
      "source": [
        "# let's see what is the token assigned for 'what'\n",
        "print(\"the token of 'what':\", vocab.stoi['what'])\n",
        "# let's see what is the token number 27\n",
        "print(\"token number 27 is:\", vocab.itos[27])\n",
        "# special tokens\n",
        "print(\"special tokens:\")\n",
        "print(\"<pad>: \", vocab.stoi['<pad>'])\n",
        "print(\"<unk>: \", vocab.stoi['<unk>'])\n",
        "# note that <sos> and <eos> should be added manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wTQE2BWD14dE",
        "outputId": "de99c622-5cde-4574-ce9f-4eef99235b42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: \n",
            "tensor([[  217,    58,    30,   173,   145,   162,     6,   144,    43,  1495,\n",
            "             8,     2,     0,     3,   400,    20,     4,     3,    56,   288,\n",
            "            20,    12,     0,   426,  1594,     5,    79,   101,   490,   782,\n",
            "             8,     2,    20,    11,    22,    58,  3165,    18,  1130,   548,\n",
            "           681, 15490,   797,     4,    31,     2,   109,     2,   109,     2,\n",
            "          1495,     8,     2,  3461,  3710,    14,     0,    16,     2,   130,\n",
            "             9,   304, 34934,    36,  3241,    12,  3165,  2424,   145,    22,\n",
            "           274,   142,  2151,  7384,  4946,    18,     9,    98,     2,   986,\n",
            "            66,   244,     6,    91,    12,   481,    37,   100,     8,  6540,\n",
            "          2244,   190,     2,     0,   750,     4,    12,  2103,     0,    18,\n",
            "            38,    48,    12,    14,  3212,    86,    67,     0,  3590,     8,\n",
            "             2,  1590,     0,     2,   782,    23,    38,     0,    44,   237,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])\n",
            "text:  there's only one thing i'm going to say about cat in the <unk> a kids movie and a good comedy movie it <unk> lost track of how many terrible jokes in the movie that not only sucked but weren't exactly kid appropriate. oh and by the way the way the cat in the hat talked was <unk> for the plot i completely forgot. who cares it sucked anyway. i'm not sure why mike myers joined but i think the writers were trying to make it sound like him in austin powers without the <unk> talk and it overly <unk> but so what it was annoying. don't see <unk> belongs in the bottom <unk> the jokes are so <unk> it's funny <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "label: \n",
            "tensor([0])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 1\n",
        "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
        "    (ds_train, ds_valid, ds_test), batch_size=batch_size, sort_key=lambda x: len(x.text), repeat=False)\n",
        "sample = next(iter(train_loader))\n",
        "print(\"tokens: \")\n",
        "print(sample.text)\n",
        "print(\"text: \", \" \".join([vocab.itos[t] for t in sample.text[0].data.cpu().numpy()]))\n",
        "print(\"label: \")\n",
        "print(sample.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNu6cqjV14dG"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/translate-app.png\" style=\"height:50px;display:inline\"> Evaluation in NLP - Perplexity and BLEU\n",
        "---\n",
        "#### Perplexity\n",
        "---\n",
        "**Perplexity** measures the language model quality. **A better language model should allow us to predict the next token more accurately**. Thus, it should allow us to spend fewer bits in compressing the sequence. We can measure it by the cross-entropy loss averaged over all the $n$ tokens of a sequence: $$ \\frac{1}{n}\\sum_{i=1}^n -\\log P(x_t|x_{t-1}, ..., x_1), $$ where $P$ is given by the language model and $x_t$ is the actual token observed at time step $t$ from the sequence. The **perplexity** is defined as $$ \\exp\\left(\\frac{1}{n}\\sum_{i=1}^n -\\log P(x_t|x_{t-1}, ..., x_1)\\right). $$\n",
        "* Perplexity can be best understood as the harmonic mean of the number of real choices that we have when deciding which token to pick next. \n",
        "* In the **best** case scenario, the model always perfectly estimates the probability of the label token as 1. **In this case the perplexity of the model is 1**.\n",
        "* In the **worst** case scenario, the model always predicts the probability of the label token as 0. In this situation, the perplexity is **positive infinity**.\n",
        "* At the **baseline**, the model predicts a uniform distribution over all the available tokens of the vocabulary. In this case, the perplexity equals the number of unique tokens of the vocabulary.\n",
        "    *  In fact, if we were to store the sequence without any compression, this would be the best we could do to encode it. Hence, this provides a nontrivial upper bound that any useful model must beat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W52Wkecw14dH"
      },
      "source": [
        "#### Bilingual Evaluation Understudy (BLEU) Score\n",
        "---\n",
        "* **BLEU** score is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another.\n",
        "* Scores are calculated for individual translated segments—generally sentences—by comparing them with a set of good quality reference translations. \n",
        "* Those scores are then averaged over the whole corpus to reach an estimate of the translation's overall quality. \n",
        "* **Intelligibility or grammatical correctness are not taken into account**.\n",
        "* BLEU's output is always a number between 0 and 1. \n",
        "* This value indicates how similar the candidate text is to the reference texts, with values closer to 1 representing more similar texts.\n",
        "    * Few human translations will attain a score of 1, since this would indicate that the candidate is identical to one of the reference translations. \n",
        "    * For this reason, it is not necessary to attain a score of 1. Because there are more opportunities to match, adding additional reference translations will increase the BLEU score.\n",
        "* BLEU uses a modified version of the precision score between a candidate translation and translation ground-truth (it is better to provide more than one reference), and it is based on $n$-grams.\n",
        "* <a href=\"https://en.wikipedia.org/wiki/BLEU\">Read More</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT4cq-Z214dL"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/nolan/64/re-enter-pincode.png\" style=\"height:50px;display:inline\"> Recurrent Neural Networks (RNNs)\n",
        "---\n",
        "* The idea of **Recurrent Neural Networks (RNNs)**: save the output of a particular layer and feed it back to the input in order to predict the output of the layer.\n",
        "* Every time step we maintain some state (received from the previous time step)--**hidden state**, which represents what we’ve read so far. This is combined with current word being read and used at later state. Then we repeat this process for as many time steps as we need.\n",
        "\n",
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/rnn_2.gif?raw=1\" style=\"height:200px\">\n",
        "\n",
        "* <a href=\"https://medium.com/perceptronai/recurrent-neural-network-an-introduction-for-beginners-1c13a541c906\">Image Source</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQi0MrT14dM"
      },
      "source": [
        "* Let $x$ denote the input layer, $h$ the hidden layer and $y$ the output layer.\n",
        "* Let $A, B \\text{ and } C$ be some network parameters used to improve the output of the model.\n",
        "* At any given time $t$, the current input is a combination of the input at $x(t)$ and $x(t-1)$ (through $h(t-1)$).\n",
        "\n",
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/rnn_3.gif?raw=1\" style=\"height:250px\">\n",
        "\n",
        "* <a href=\"https://www.simplilearn.com/tutorials/deep-learning-tutorial/rnn\">Image Source</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMWcsQGR14dO"
      },
      "source": [
        "#### The Hidden State of RNN Cells\n",
        "---\n",
        "* For each element in the input sequence, each layer computes the following function: $$ h_t = tanh\\left(W_{ih}x_t +b_{ih} + W_{hh}h_{(t-1)} + b_{hh}\\right), $$ where $h_t$ is the hidden state at time $t$, $x_t$ is the input at time $t$, and $h_{(t-1)}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time 0.\n",
        "\n",
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/rnn_4.gif?raw=1\" style=\"height:250px\">\n",
        "\n",
        "* Image by Michael Nguyen\n",
        "\n",
        "* In PyTorch: <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\">`torch.nn.RNN(input_size, hidden_size, num_layers...)`</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MYo9Xx-14dO"
      },
      "source": [
        "#### Disadvantages of RNNs\n",
        "---\n",
        "* The whole history of the document reading is compressed into a fixed-size vector at each time step, which is the bottleneck of this model.\n",
        "* **Gradients tend to vanish** with long contexts.\n",
        "* Not possible to parallelize over time-steps, so **slow training**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_1glJtD14dP"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/nolan/64/time-machine.png\" style=\"height:50px;display:inline\"> Backpropagation Through Time (BPTT)\n",
        "---\n",
        "* **Forward propagation** in an RNN is relatively straightforward and is the same as MLPs (but delayed, as we need the previous output).\n",
        "* **Backpropagation through time (BPTT)**: a specific application of backpropagation in RNNs. \n",
        "* BPTT requires us to expand or *unroll* the computational graph of an RNN one time step at a time to obtain the dependencies among model variables and parameters.\n",
        "* Then, based on the chain rule, we apply backpropagation to compute and store gradients. \n",
        "    * Since sequences can be rather long, the dependency can be rather lengthy. \n",
        "    * For instance, for a sequence of 1000 characters, the first token could potentially have significant influence on the token at the final position. This is not really computationally feasible (it takes too long and requires too much memory) and it requires over 1000 matrix products before we would arrive at that very elusive gradient.\n",
        "* High powers of matrices can lead to **divergent or vanishing eigenvalues -- exploding or vanishing gradients**.\n",
        "* For efficient computation, **intermediate values are cached** during backpropagation through time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4CxYkCE14dQ"
      },
      "source": [
        "#### Computing Gradients in BPTT\n",
        "---\n",
        "* Consider an RNN *without* bias parameters, whose activation function in the hidden layer uses the identity mapping ( $\\phi(x)=x$ ). \n",
        "* For time step $t$ , let the single example input and the label be $x_t\\in \\mathbb{R}^d$ and $y_t$ , respectively.\n",
        "* The hidden state  $h_t\\in \\mathbb{R}^h$  and the output $o_t\\in \\mathbb{R}^q$  are computed as: $$ h_t=W_{hx}x_t+W_{hh}h_{t−1}, $$ $$ o_t = W_{qh}h_t, $$ where $W_{hx}\\in \\mathbb{R}^{h\\times d}$,  $W_{hh}\\in \\mathbb{R}^{h\\times h}$, and $W_{qh}\\in \\mathbb{R}^{q\\times h}$ are the weight parameters.\n",
        "* Denote by $l(o_t,y_t)$ the loss at time step $t$. Our objective function, the loss over $T$ time steps from the beginning of the sequence is thus: $$ L = \\frac{1}{T}\\sum_{t=1}^T l(o_t,y_t).$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAYJMvsQ14dR"
      },
      "source": [
        "* Computational graph for 3 time steps:\n",
        "\n",
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/bptt_1.svg?raw=1\" style=\"height:250px\">\n",
        "\n",
        "* For example, the computation of the hidden states of time step 3,  $h_3$ , depends on the model parameters $W_{hx}$ and $W_{hh}$, the hidden state of the last time step $h_2$, and the input of the current time step $x_3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDSN1l8p14dR"
      },
      "source": [
        "* According to the dependencies in the graph, we can traverse in the opposite direction of the arrows to calculate and store the gradients in turn. We can look at this as unrolled backpropagation.\n",
        "* Differentiating the objective function with respect to the model output at any time step $t$ is straightforward: $$ \\frac{\\partial L}{\\partial o_t} = \\frac{\\partial l(o_t, y_t)}{T\\cdot \\partial o_t} \\in \\mathbb{R}^q.$$\n",
        "* Now, we can calculate the gradient of the objective function with respect to the parameter $W_{qh}$ in the output layer. Note that the objective function $L$ depends on $W_{qh}$ via $o_1,…,o_T$: $$ \\frac{\\partial L}{\\partial W_{qh}}=\\sum_{t=1}^T \\text{prod} \\left(\\frac{\\partial L}{\\partial o_t}, \\frac{\\partial o_t}{\\partial W_{qh}} \\right) = \\sum_{t=1}^T \\frac{\\partial L}{\\partial o_t}h_t^T $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9MBNq_x14dS"
      },
      "source": [
        "* We continue back down the graph, and we need the derivatives w.r.t $h_t$.\n",
        "* At the final time step $T$ the objective function $L$ depends on the hidden state $h_T$ only via $o_T$: $$ \\frac{\\partial L}{\\partial h_T} = \\text{prod}\\left(\\frac{\\partial L}{\\partial o_T}, \\frac{\\partial o_T}{\\partial h_T} \\right) = W_{qh}^T \\frac{\\partial L}{\\partial o_T}\\in \\mathbb{R}^h. $$\n",
        "* It gets trickier for any time step $t<T$, where the objective function $L$ depends on $h_t$ via $h_{t+1}$ and $o_t$. According to the chain rule: $$\\frac{\\partial L}{\\partial h_t} = \\text{prod}\\left(\\frac{\\partial L}{\\partial h_{t+1}}, \\frac{\\partial h_{t+1}}{\\partial h_t} \\right) + \\text{prod}\\left(\\frac{\\partial L}{\\partial o_t}, \\frac{\\partial o_t}{\\partial h_t} \\right) = W_{hh}^T\\frac{\\partial L}{\\partial h_{t+1}} + W_{qh}^T\\frac{\\partial L}{\\partial o_t}. $$\n",
        "* (EXERCISE) Expanding the recurrent computation for any time step $1\\leq t \\leq T$ gives: $$ \\frac{\\partial L}{\\partial h_t} = \\sum_{i=t}^T \\left(W_{hh}^T \\right)^{T-i}W_{qh}^T\\frac{\\partial L}{\\partial o_{T+t-i}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6KhPvPm14dS"
      },
      "source": [
        "* Notice that the simple linear equation already exhibits some key problems of long sequence models: it involves potentially very large powers of $W_{hh}^T$. \n",
        "* In it, eigenvalues smaller than 1 **vanish** and eigenvalues larger than 1 **diverge**. This is numerically unstable, which manifests itself in the form of **vanishing and exploding gradients**. \n",
        "* One way to address this is to **truncate** the time steps at a computationally convenient size. In practice, this truncation is effected by detaching the gradient after a given number of time steps.\n",
        "* GRUs and LSTMs cells can alleviate this better as we will soon see."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjveSDVQ14dU"
      },
      "source": [
        "* Finally, the objective function $L$ depends on model parameters $W_{hx}$ and $W_{hh}$ in the hidden layer via hidden states  $h_1,…,h_T$: $$ \\frac{\\partial L}{\\partial W_{hx}} = \\sum_{i=t}^T \\text{prod}\\left(\\frac{\\partial L}{\\partial h_t}, \\frac{\\partial h_t}{\\partial W_{hx}} \\right) = \\sum_{i=t}^T \\frac{\\partial L}{\\partial h_t}x_t^T, $$\n",
        "$$ \\frac{\\partial L}{\\partial W_{hh}} = \\sum_{i=t}^T \\text{prod}\\left(\\frac{\\partial L}{\\partial h_t}, \\frac{\\partial h_t}{\\partial W_{hh}} \\right) = \\sum_{i=t}^T \\frac{\\partial L}{\\partial h_t}h_{t-1}^T$$\n",
        "\n",
        "* BPTT computes and stores the above gradients in turn. Specifically, stored intermediate values are reused to avoid duplicate calculations, such as storing  $\\frac{\\partial L}{\\partial h_t}$ to be used in computation of both $\\frac{\\partial L}{\\partial W_{hx}}$ and $\\frac{\\partial L}{\\partial W_{hh}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEEfBPkJ14dW"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/memory-slot.png\" style=\"height:50px;display:inline\"> Long Term Short Memory (LSTM)\n",
        "---\n",
        "* As mentioned before, during backpropagation, RNNs suffer from the vanishing gradient problem, which essentially creates a **short memory**.\n",
        "* Long short-term memory (LSTM) is a type of recurrent cell that tries to preserve long term information. The idea of LSTM was presented back in 1997, but flourished in the age of deep learning.\n",
        "* LSTM introduces a memory cell that has the same shape as the hidden state, engineered to record additional information.\n",
        "* The memory is controlled by 3 main gates: \n",
        "    * **Input gate**: decides when to read data into the cell.\n",
        "    * **Output gate**: outputs the entries from the cell.\n",
        "    * **Forget gate**: a mechanism to reset the content of the cell.\n",
        "* These gates learn which information is relevant to forget or remember during the training process. The gates contain a sigmoid activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUsSj86h14dZ"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/lstm_1.svg?raw=1\" style=\"height:250px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqkrttuU14da"
      },
      "source": [
        "* Suppose that there are $h$ hidden units, the batch size is $n$, and the number of inputs is $d$. Thus, the input is $X_t\\in \\mathbb{R}^{n\\times d}$ (number of examples: $n$, number of inputs: $d$) and the hidden state of the previous time step is $H_{t-1}\\in\\mathbb{R}^{n\\times h}$ (number of hidden units: $h$). We define the following at timestep $t$:\n",
        "    * **Input gate**: $$ I_t = \\sigma(X_tW_{xi} +H_{t-1}W_{hi} +b_i) \\in \\mathbb{R}^{n\\times h},$$\n",
        "    * **Forget gate**: $$ F_t = \\sigma(X_tW_{xf} +H_{t-1}W_{hf} +b_f) \\in \\mathbb{R}^{n\\times f}, $$\n",
        "    * **Output gate**: $$ O_t = \\sigma(X_tW_{xo} +H_{t-1}W_{ho} +b_o) \\in \\mathbb{R}^{n\\times o}, $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8aJ0Rhw14da"
      },
      "source": [
        "#### Memory Cell\n",
        "---\n",
        "* The candidate memory cell $\\tilde{C}_t$ is defined as follows: $$ \\tilde{C}_t = \\text{tanh}(X_tW_{xc} +H_{t-1}W_{hc} +b_c) \\in \\mathbb{R}^{n\\times c}$$\n",
        "    * Note the difference in notations: a candidate memory is denoted with $\\tilde{\\cdot}$ while the actual memory is without the tilde.\n",
        "* The input gate $I_t$ governs how much we take new data into account via $\\tilde{C}_t$ and the forget gate $F_t$ addresses how much of the old memory cell content $C_{t-1}$ we retain. This yields: $$ C_t = F_t \\odot C_{t-1} + I_{t} \\odot \\tilde{C}_t$$\n",
        "    * $\\odot$ is the element-wise product operator (Hadamard).\n",
        "* If the forget gate is always approximately 1 and the input gate is always approximately 0, the past memory cells $C_{t-1}$ will be saved over time and passed to the current time step. \n",
        "* This design is introduced to alleviate the vanishing gradient problem and to better capture long range dependencies within sequences.\n",
        "* Finally, the hidden state at time $t$: $$ H_t = O_t \\odot \\text{tanh}(C_t).$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDtv4gh_14db"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/lstm_2.gif?raw=1\" style=\"height:350px\">\n",
        "\n",
        "* <a href=\"https://becominghuman.ai/long-short-term-memory-part-1-3caca9889bbc\">Image Source</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "f5EtatoU14db",
        "outputId": "49f3730f-f5fc-43cf-b5a1-8d8848855028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes: output - torch.Size([5, 3, 20]), hidden - torch.Size([2, 3, 20]), memory - torch.Size([2, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "rnn = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)\n",
        "x = torch.randn(5, 3, 10)  # 5 words per senetence, 3 sentences (batch_size), embedding dimension of each word is 10\n",
        "h0 = torch.randn(2, 3, 20)  # initialize hidden states per layer\n",
        "c0 = torch.randn(2, 3, 20)  # initialize memory per layer\n",
        "output, (hn, cn) = rnn(x, (h0, c0))\n",
        "print(f'shapes: output - {output.shape}, hidden - {hn.shape}, memory - {cn.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cytVSFsz14dc"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/96/000000/front-gate-open.png\" style=\"height:50px;display:inline\"> Gated Recurrent Unit (GRU)\n",
        "---\n",
        "* Unlike regular RNNs, Gated Recurrent Units (GRUs) support gating of the hidden state.\n",
        "* GRUs have two mechanism to control when a hidden state should be updated, **update gate** and also when it should be reset, **reset gate**.\n",
        "* **Reset gate**: allows to control how much of the previous state should be remembered, helps capture short-term dependencies in sequences.\n",
        "* **Update gate**: allows to control how much of the new state is just a copy of the old state, help capture long-term dependencies in sequences.\n",
        "* Unlike LSTMS, GRUs don't have a memory component, and thus are much faster to update (which results in faster training), but usually LSTMs perform better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsDSJaVZ14de"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/gru_1.svg?raw=1\" style=\"height:300px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SNtj8Sj14de"
      },
      "source": [
        "* Suppose that the input is a mini-batch $X_t \\in \\mathbb{R}^{n\\times d}$ for a given time step $t$ and the hidden state of the previous time step is $H_{t−1}\\in \\mathbb{R}^{n\\times h}$.\n",
        "* The reset gate $R_t \\in \\mathbb{R}^{n \\times h}$ and update gate $Z_t \\in \\mathbb{R}^{n \\times h}$ are computed as follows: $$ R_t = \\sigma(X_tW_{xr} + H_{t-1}W_{hr} +b_r), $$ $$ Z_t = \\sigma(X_tW_{xz} + H_{t-1}W_{hz} +b_z), $$ where $W_{xr}, W_{xz} \\in \\mathbb{R}^{d \\times h}$ and $W_{hr}, W_{hz} \\in \\mathbb{R}^{h \\times h}$ are weight parameters, and $b_r, b_z \\in \\mathbb{R}^{1 \\times h}$ are biases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ5rcRCX14df"
      },
      "source": [
        "#### GRUs Hidden State\n",
        "---\n",
        "* The *candidate* hidden state $\\tilde{H}_{t} \\in \\mathbb{R}^{n \\times h}$ at timestep $t$ is defined as: $$ \\tilde{H}_{t} = \\text{tanh}\\left(X_t W_{xh} + (R_t \\odot H_{t-1})W_{hh} \\right) + b_h$$\n",
        "    * The result is a candidate since we still need to incorporate the action of the *update gate*.\n",
        "* Finally, the new hidden state $H_t$ and the final update to the GRU in timestep $t$: $$ H_t = Z_t \\odot H_{t-1} +(1-Z_t) \\odot \\tilde{H}_t. $$\n",
        "* Whenever the update gate $Z_t$ is close to 1, we simply retain the old state. In this case the information from $X_t$ is essentially ignored, effectively skipping time step $t$ in the dependency chain. \n",
        "* In contrast, whenever $Z_t$ is close to 0, the new latent state $H_t$ approaches the candidate latent state $\\tilde{H}_t$.\n",
        "* These designs can help us cope with the vanishing gradient problem in RNNs and better capture dependencies for sequences with large time step distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5BVrIgQo14dg",
        "outputId": "f621982b-4a92-4922-ebb3-7bef1a1a02e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes: output - torch.Size([5, 3, 20]), hidden - torch.Size([2, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "rnn = nn.GRU(input_size=10, hidden_size=20, num_layers=2)  \n",
        "x = torch.randn(5, 3, 10)  # 5 words per senetence, 3 sentences (batch_size), embedding dimension of each word is 10\n",
        "h0 = torch.randn(2, 3, 20)  # initialize hidden states per layer\n",
        "output, hn = rnn(x, h0)\n",
        "print(f'shapes: output - {output.shape}, hidden - {hn.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwV_6NPx14dg"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/fire-element.png\" style=\"height:50px;display:inline\"> PyTorch RNN Model Example\n",
        "----\n",
        "Following is an example of building a classifier with LSTMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Q1D6tnpR14dh"
      },
      "outputs": [],
      "source": [
        "# https://github.com/FernandoLpz/Text-Classification-LSTMs-PyTorch\n",
        "class TweetClassifier(nn.ModuleList):\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super(TweetClassifier, self).__init__()\n",
        "\n",
        "        self.batch_size = args.batch_size\n",
        "        self.hidden_dim = args.hidden_dim\n",
        "        self.LSTM_layers = args.lstm_layers\n",
        "        self.input_size = args.max_words  # embedding dimension\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.embedding = nn.Embedding(self.input_size, self.hidden_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, num_layers=self.LSTM_layers,\n",
        "                            batch_first=True)  # NOTE: batch_first=True:\n",
        "        # input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature).\n",
        "        self.fc1 = nn.Linear(in_features=self.hidden_dim, out_features=257)\n",
        "        self.fc2 = nn.Linear(257, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim))\n",
        "        c = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim))\n",
        "\n",
        "        torch.nn.init.xavier_normal_(h)\n",
        "        torch.nn.init.xavier_normal_(c)\n",
        "\n",
        "        out = self.embedding(x)\n",
        "        out, (hidden, cell) = self.lstm(out, (h, c))\n",
        "        out = self.dropout(out)\n",
        "        out = torch.relu_(self.fc1(out[:, -1, :]))\n",
        "        out = self.dropout(out)\n",
        "        out = torch.sigmoid(self.fc2(out))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzOZ9vcd14di"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/cute-clipart/64/000000/alarm.png\" style=\"height:50px;display:inline\"> Attention\n",
        "---\n",
        "* **Attention** is a generalized pooling method with bias alignment over inputs. \n",
        "* An input of the attention layer is called a **query**. \n",
        "* For a query, attention returns an output based on the memory — a set of **key-value** pairs encoded in the attention layer.\n",
        "* There are two main types of attention: **self-attention** and **cross-attention**, and in each type we can define **hard** attention or **soft** attention.\n",
        "* Our foucs will be **self-attention**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOuYD3Rm14dj"
      },
      "source": [
        "* Consider a set of $t$ input $x$'s, where $x_i \\in \\mathbb{R}^n$. This set can be represented as the matrix $X \\in \\mathbb{R}^{n \\times t}$.\n",
        "* In self-attention, we define the hidden representation $h$ as a linear combination of the inputs: $$ h = \\alpha_1 x_1 +...\\alpha_t x_t $$\n",
        "* Using the matrix representation described above, and stacking all the $\\alpha$'s is a vector $a \\in \\mathbb{R}^{t}$ we can write the hidden layer as the matrix product: $ h=Xa \\in \\mathbb{R}^n $\n",
        "* Depending on the constraints we impose on the vector $a$, we can achieve hard or soft attention.\n",
        "* **Hard attention**: we impose the following constraint on the alphas: $||a||_0=1$, which means that $a$ is a one-hot vector. That is the hidden representation reduces to the input $x_i$ corresponding to the element $\\alpha_i=1$.\n",
        "* **Soft attention**: With soft attention, we impose that $||a||_1=1$. The hidden representations is a linear combination of the inputs where the coefficients sum up to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MpK9r8j14dj"
      },
      "source": [
        "#### Obtaining $\\alpha_i$'s\n",
        "---\n",
        "* **Hard attention**: $$a = \\text{argmax}(X^Tx_i) \\in \\mathbb{R}^t $$\n",
        "    * We get a one-hot vector of alphas.\n",
        "* **Soft attention**: $$ a = \\text{soft(arg)max}(X^Tx_i) \\in \\mathbb{R}^t  $$\n",
        "    * The components of the resulting vector $a$ sum to 1.\n",
        "* The components of the vector $a$ are also called “scores” because the scalar product between two vectors tells us how aligned or similar two vectors are. \n",
        "* Therefore, the elements of $a$ provide information about the similarity of the overall set to a particular $x_i$.\n",
        "* Generating $a$ this way gives a set of them, one for each $x_i$. Moreover, each $a_i \\in \\mathbb{R}^t$ so we can stack the alphas in a matrix $A \\in \\mathbb{R}^{t \\times t}$.\n",
        "* Since each hidden state is a linear combination of the inputs $X$ and a vector $a$, we obtain a set of $t$ hidden states, which we can stack into a matrix $H \\in \\mathbb{R}^{n \\times t}$: $$ H = XA $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5FpvU-114dk"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/attn_3.png?raw=1\" style=\"height:300px\">\n",
        "\n",
        "* Visualization of the outputs upon using two heads.\n",
        "* We can see that if the Query word is **it**, the first head focuses more on the words **the animal**, and the second head focuses more on the word **tired**. \n",
        "* Hence, the final context representation will be focusing on all the words **the, animal** and **tired**, and thus is a superior representation as compared to the traditional way.\n",
        "* <a href=\"https://blogs.oracle.com/datascience/multi-head-self-attention-in-nlp\">Images Source</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLczhcOx14dl"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/nolan/64/key.png\" style=\"height:50px;display:inline\"> Attention with Key-Value Mechanism\n",
        "---\n",
        "* Now that we have a way to calculate scores based on similarity, we apply it in a key-value fashion.\n",
        "* A key-value store is a paradigm designed for storing (saving), retrieving (querying) and managing associative arrays (dictionaries / hash tables).\n",
        "* Imaginative example: the Lasagne recipe \n",
        "    * **Query**: say we wanted to find a recipe to make lasagne. We have a recipe book and search for “lasagne” - this is the **query**. \n",
        "    * **Key**: this query is checked against all possible **keys** in your dataset - in this case, this could be the titles of all the recipes in the book. \n",
        "    * We check how aligned the query is with each title to find the maximum matching score between the query and all the respective keys. \n",
        "    * **Value**: If our output is the argmax function - we retrieve the *single* recipe (value) with the highest score. Otherwise, if we use a soft argmax function, we would get a probability distribution and can retrieve in order from the most similar content to less and less relevant recipes matching the query.\n",
        "    * Summary: keys and queries - titles of recipes, values - the actual recipe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93YdzEXV14dl"
      },
      "source": [
        "#### Queries, Keys and Values\n",
        "---\n",
        "* We denote the vectors $q ,k$ and $v$ as the query, key and value vectors, respectively and their corresponding learnable parameters matrices $W_{q}, W_k$ and $W_v$: $$ q = W_q x $$ $$ k = W_k x $$ $$ v = W_v x $$\n",
        "*  We also do not include any non-linearities since attention is completely based on **orientation**.\n",
        "* In order to compare the query against all possible keys, $q$ and $k$ must have the same dimensionality, i.e. $q, k \\in \\mathbb{R}^d$.\n",
        "* $v$ can be of any dimension, $v \\in \\mathbb{R}^{d_v}$. \n",
        "    * In the lasagne recipe example - we need the query to have the dimension as the keys, i.e. the titles of the different recipes that we’re searching through. The dimension of the corresponding recipe retrieved, $v$, can be arbitrarily long though.\n",
        "* For simplicity, we will assume that everything has the same dimension $d$ ($d_v =d$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iMqRJQV14dn"
      },
      "source": [
        "* Given a set of $x$'s, a set of queries, a set of keys and a set of values, we can stack these sets into matrices each with $t$ columns since we stacked $t$ vectors; each vector has height $d$: $$ \\{x_i\\}_{i=1}^t \\to \\{q_i\\}_{i=1}^t, \\{k_i\\}_{i=1}^t, \\{v_i\\}_{i=1}^t \\to Q, K, V \\in \\mathbb{R}^{d \\times t} $$\n",
        "* We compare one query $q$ against the matrix of all keys $K$: $$ a = \\text{[soft]argmax}(K^T q) \\in \\mathbb{R}^t $$\n",
        "* Then the hidden layer is going to be the linear combination of the columns of $V$ weighted by the coefficients in $a$: $$ h=Va \\in \\mathbb{R}^{d} $$\n",
        "* Since we have $t$ queries, we’ll get $t$ corresponding $a$ weights and therefore a matrix $A \\in \\mathbb{R}^{t \\times t}$, which yields: $$ H = VA \\in \\mathbb{R}^{d \\times t}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAjNDLAC14do"
      },
      "source": [
        "* For implementation, we can speed up computation by stacking all the $W$’s into one tall $W$ and then calculate $q, k, v$ in one go: $$ \\begin{bmatrix} q \\\\ k \\\\ v \\end{bmatrix} = \\begin{bmatrix}W_q \\\\ W_k \\\\ W_v\\end{bmatrix} x \\in \\mathbb{R}^{3d} $$\n",
        "* **Multi-head Attention**: one \"head\" of attention corresponds to one dictionary of queries, keys values. For $h$ heads of attention we have $h$ $q$’s, $h$ $k$’s and $h$ $v$’s and we end up with a vector: $$  \\begin{bmatrix} q^1 \\\\ \\vdots \\\\ q^h \\\\ k^1 \\\\ \\vdots \\\\ k^h \\\\ v^1 \\\\ \\vdots \\\\ v^h \\end{bmatrix} = \\begin{bmatrix}W_q^1 \\\\ \\vdots \\\\ W_q^h \\\\ W_k^1 \\\\ \\vdots \\\\ W_k^h \\\\ W_v^1 \\\\ \\vdots \\\\  W_v^h\\end{bmatrix} x \\in \\mathbb{R}^{3hd} $$\n",
        "* We can still transform the multi-headed values to have the original dimension $\\mathbb{R}^{d}$ by using a $W_h \\in \\mathbb{R}^{d \\times hd}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUu1g3Gu14dp"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/attn_1.png?raw=1\" style=\"height:200px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTSt1-De14dp"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/attn_2.svg?raw=1\" style=\"height:350px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QWr22s2814dq"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, dropout, d_input=None):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        if d_input is None:\n",
        "            d_xq = d_xk = d_xv = d_model\n",
        "        else:\n",
        "            d_xq, d_xk, d_xv = d_input\n",
        "            \n",
        "        # Make sure that the embedding dimension of model is a multiple of number of heads\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.d_k = d_model // self.num_heads\n",
        "\n",
        "        print(f\"self.d_model = {self.d_model}\")\n",
        "        print(f\"self.num_heads = {self.num_heads}\")\n",
        "        print(f\"self.d_k = {self.d_k}\")\n",
        "\n",
        "        # These are still of dimension d_model. They will be split into number of heads \n",
        "        self.W_q = nn.Linear(d_xq, d_model, bias=False)\n",
        "        self.W_k = nn.Linear(d_xk, d_model, bias=False)\n",
        "        self.W_v = nn.Linear(d_xv, d_model, bias=False)\n",
        "        \n",
        "        # Outputs of all sub-layers need to be of dimension d_model\n",
        "        self.W_h = nn.Linear(d_model, d_model)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def scaled_dot_product_attention(self, Q, K, V):\n",
        "        batch_size = Q.size(0) \n",
        "        k_length = K.size(-2) \n",
        "        print(f\"k_length = {k_length}\")\n",
        "        \n",
        "        # Scaling by d_k so that the soft(arg)max doesnt saturate\n",
        "        Q = Q / np.sqrt(self.d_k)                         # (bs, n_heads, q_length, dim_per_head)\n",
        "        scores = torch.matmul(Q, K.transpose(2,3))          # (bs, n_heads, q_length, k_length)\n",
        "        print(f\"scores.size() = {scores.size()}\")\n",
        "        #print(f\"scores = {scores}\")\n",
        "        \n",
        "        A = torch.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)\n",
        "        print(f\"A.size() = {A.size()}\")\n",
        "        A = self.dropout(A)\n",
        "        \n",
        "        # Get the weighted average of the values\n",
        "        H = torch.matmul(A, V)     # (bs, n_heads, q_length, dim_per_head)\n",
        "\n",
        "        return H, A \n",
        "\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"\n",
        "        Split the last dimension into (heads X depth)\n",
        "        Return after transpose to put in shape (batch_size X num_heads X seq_length X d_k)\n",
        "        \"\"\"\n",
        "        print(f\"x.size() = {x.size()}\")\n",
        "        z = x.view(batch_size, -1, self.num_heads, self.d_k)\n",
        "        print(f\"z.size() = {z.size()}\")\n",
        "        y = z.transpose(1, 2)\n",
        "        print(f\"y.size() = {y.size()}\")\n",
        "        return y\n",
        "\n",
        "    def group_heads(self, x, batch_size):\n",
        "        \"\"\"\n",
        "        Combine the heads again to get (batch_size X seq_length X (num_heads times d_k))\n",
        "        \"\"\"\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
        "    \n",
        "\n",
        "    def forward(self, X_q, X_k, X_v):\n",
        "        batch_size, seq_length, dim = X_q.size()\n",
        "\n",
        "        print(f\"X_q.size() = {X_q.size()}\")\n",
        "\n",
        "        # After transforming, split into num_heads \n",
        "        Q = self.split_heads(self.W_q(X_q), batch_size)  # (bs, n_heads, q_length, dim_per_head)\n",
        "        K = self.split_heads(self.W_k(X_k), batch_size)  # (bs, n_heads, k_length, dim_per_head)\n",
        "        V = self.split_heads(self.W_v(X_v), batch_size)  # (bs, n_heads, v_length, dim_per_head)\n",
        "\n",
        "        print(f\"Q.size() = {Q.size()}\")\n",
        "        print(f\"K.size() = {K.size()}\")\n",
        "        print(f\"V.size() = {V.size()}\")\n",
        "\n",
        "        # Calculate the attention weights for each of the heads\n",
        "        H_cat, A = self.scaled_dot_product_attention(Q, K, V)\n",
        "        print(f\"H_cat.size() = {H_cat.size()}\")\n",
        "        \n",
        "        # Put all the heads back together by concat\n",
        "        H_cat = self.group_heads(H_cat, batch_size)    # (bs, q_length, dim)\n",
        "        print(f\"H_cat.size() = {H_cat.size()}\")\n",
        "        \n",
        "        # Final linear layer  \n",
        "        H = self.W_h(H_cat)          # (bs, q_length, dim)\n",
        "        print(f\"H.size() = {H.size()}\")\n",
        "        \n",
        "        return H, A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX1r0b_I14dr"
      },
      "source": [
        "#### Self-Attention Sanity Check\n",
        "---\n",
        "* If the query matches with one of the key values, it should have all the attention focused there, with the value returned as the value at that index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tHTjO07h14ds",
        "outputId": "bea4861a-231f-4b77-b1c3-f5417aba8f49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.d_model = 512\n",
            "self.num_heads = 8\n",
            "self.d_k = 64\n",
            "k_length = 4\n",
            "scores.size() = torch.Size([1, 1, 1, 4])\n",
            "A.size() = torch.Size([1, 1, 1, 4])\n",
            "Attention weights are: tensor([3.7266e-06, 9.9999e-01, 3.7266e-06, 3.7266e-06])\n",
            "Output is: tensor([1.0004e+01, 4.0993e-05, 0.0000e+00])\n",
            "self.d_model = 32\n",
            "self.num_heads = 8\n",
            "self.d_k = 4\n",
            "X_q.size() = torch.Size([1, 5, 7])\n",
            "x.size() = torch.Size([1, 5, 32])\n",
            "z.size() = torch.Size([1, 5, 8, 4])\n",
            "y.size() = torch.Size([1, 8, 5, 4])\n",
            "x.size() = torch.Size([1, 5, 32])\n",
            "z.size() = torch.Size([1, 5, 8, 4])\n",
            "y.size() = torch.Size([1, 8, 5, 4])\n",
            "x.size() = torch.Size([1, 5, 32])\n",
            "z.size() = torch.Size([1, 5, 8, 4])\n",
            "y.size() = torch.Size([1, 8, 5, 4])\n",
            "Q.size() = torch.Size([1, 8, 5, 4])\n",
            "K.size() = torch.Size([1, 8, 5, 4])\n",
            "V.size() = torch.Size([1, 8, 5, 4])\n",
            "k_length = 5\n",
            "scores.size() = torch.Size([1, 8, 5, 5])\n",
            "A.size() = torch.Size([1, 8, 5, 5])\n",
            "H_cat.size() = torch.Size([1, 8, 5, 4])\n",
            "H_cat.size() = torch.Size([1, 5, 32])\n",
            "H.size() = torch.Size([1, 5, 32])\n"
          ]
        }
      ],
      "source": [
        "def print_out(Q, K, V):\n",
        "    temp_out, temp_attn = temp_mha.scaled_dot_product_attention(Q, K, V)\n",
        "    print('Attention weights are:', temp_attn.squeeze())\n",
        "    print('Output is:', temp_out.squeeze())\n",
        "    \n",
        "\n",
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8, dropout=0)\n",
        "test_K = torch.tensor(\n",
        "    [[10, 0, 0],\n",
        "     [ 0,10, 0],\n",
        "     [ 0, 0,10],\n",
        "     [ 0, 0,10]]\n",
        ").float()[None, None]\n",
        "\n",
        "#print(test_K)\n",
        "#print(test_K.size())\n",
        "test_V = torch.tensor(\n",
        "    [[   1,0,0],\n",
        "     [  10,0,0],\n",
        "     [ 100,5,0],\n",
        "     [1000,6,0]]\n",
        ").float()[None, None]\n",
        "\n",
        "test_Q = torch.tensor(\n",
        "    [[0, 10, 0]]\n",
        ").float()[None, None]\n",
        "print_out(test_Q, test_K, test_V)\n",
        "\n",
        "\n",
        "temp_mha2 = MultiHeadAttention(d_model=32, num_heads=8, dropout=0, d_input=(7,7,30))\n",
        "X = torch.tensor(\n",
        "    np.random.randn(5,7)\n",
        ").float()[None]\n",
        "X_v = torch.tensor(\n",
        "    np.random.randn(5,30)\n",
        ").float()[None]\n",
        "\n",
        "output = temp_mha2(X,X,X_v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IM41kfq14dt"
      },
      "source": [
        "Great! We can see that it focuses on the second key and returns the second value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Inze3dOC14dt"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/96/000000/transformer.png\" style=\"height:50px;display:inline\"> The Transformer\n",
        "---\n",
        "* **Transformer**: attention-based encoder-decoder architecture that aims to combine the advantages from both CNNs and RNNs.\n",
        "* It achieves parallelization by capturing recurrence sequence with attention and at the same time encodes each item’s position in the sequence.\n",
        "    * RNNs are replaced with multi-head attention layers, incorporating the position-wise information through position encoding, and applying layer normalization. \n",
        "* A compatible model with significantly shorter training time.\n",
        "* 3 mains stages: input stage, $n$ times transformer blocks (encoding layers) with different parameters, output stage.\n",
        "* Sequence-to-Sequence (seq2seq) models also require a decoder module, which is why the Transformer can be split into an encoder part and a decoder part.\n",
        "* We will now take a look at each component of the Transformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MZgro_D14du"
      },
      "source": [
        "#### Transformer's Encoder Module\n",
        "---\n",
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/transformer_enc.png?raw=1\" style=\"height:300px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geHvAw9514dv"
      },
      "source": [
        "* The encoder module accepts a set of inputs $\\{x_i\\}_{i=1}^t$, which are simultaneously fed through the **self-attention** block and bypass it to reach the `Add, Norm` block.\n",
        "    *  In tasks that try to model sequential data, **positional encodings** are added prior to self-attetion layer.\n",
        "    * The `Add, Norm` block has two components: the add block is a residual connection, and then layer normalization.\n",
        "* At which point, they are again simultaneously passed through the 1D-Convolution and another `Add, Norm` block, and consequently outputted as the set of hidden representation $\\{h_i^{Enc}\\}_{i=1}^t$.\n",
        "    * 1D-convolution (a position-wise feed forward network): consists of two dense layers. Depending on what values are set, this block allows you to adjust the dimensions of the output $h^{Enc}$.\n",
        "    * Similar to the multi-head attention, the position-wise feed-forward network (1x1 convolution) will only change the last dimension size of the input—the feature dimension. \n",
        "    * In addition, if two items in the input sequence are identical, the according outputs will be identical as well.\n",
        "* This set of hidden representation is then either sent through an arbitrary number of encoder modules (i.e. more layers), or to the *decoder*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCsziyuN14dv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1-D (1x1) Convolution: an MLP with one hidden layer and ReLU activation applied to each and every element in the set.\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, d_model, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.k1convL1 = nn.Linear(d_model, hidden_dim)\n",
        "        self.k1convL2 = nn.Linear(hidden_dim, d_model)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.k1convL1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.k1convL2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3_DroDf14dw",
        "outputId": "ed378ea8-1709-43b2-cea2-c997a4925e6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.3550,  0.2051,  0.3242, -0.1092],\n",
              "        [-0.3550,  0.2051,  0.3242, -0.1092],\n",
              "        [-0.3550,  0.2051,  0.3242, -0.1092]], grad_fn=<SelectBackward>)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ffn = CNN(4, 8)\n",
        "ffn.eval()\n",
        "ffn(torch.ones((2, 3, 4)))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymQE16UY14dw"
      },
      "source": [
        "#### Positional Encoding\n",
        "---\n",
        "* Unlike the recurrent layer, both the multi-head attention layer and the position-wise feed-forward network compute the output of each item in the sequence independently. \n",
        "* This feature enables us to **parallelize the computation**, but it fails to model the sequential information for a given sequence. \n",
        "* To better capture the sequential information, the Transformer model uses the positional encoding to **maintain the positional information of the input sequence**.\n",
        "    * The positional encoding adds positional information. This can be implemented in multiple ways, and the Transformer uses `sin` and `cos` functions to add that information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd5RWCLW14dx"
      },
      "source": [
        "* Assume that $X\\in \\mathbb{R}^{l\\times d}$ is the embedding of an example, where $l$ is the sequence length and $d$ is the embedding size. \n",
        "* This positional encoding layer encodes $X$’s position $P\\in \\mathbb{R}^{l\\times d}$ and outputs $P+X$.\n",
        "* The position $P$ is a 2-D matrix, where $i$ refers to the order in the sentence, and $j$ refers to the position along the embedding vector dimension. \n",
        "* In this way, each value in the origin sequence is then maintained using the equations below: $$ P_{i, 2j} = \\sin(i/10000^{2j/d}), $$ $$ P_{i, 2j+1} = \\cos(i/10000^{2j/d}) $$ for $i=0,…,l−1$ and $j=0,…,\\lfloor(d−1)/2\\rfloor$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw6-wX7Q14dy"
      },
      "source": [
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/transformer_position_enc.svg?raw=1\" style=\"height:200px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhKginF-14dy"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Create a long enough `P`\n",
        "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
        "        X = torch.arange(0, max_len, dtype=torch.float32).reshape(-1, 1)\n",
        "        X = X / torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
        "        self.P[:, :, 0::2] = torch.sin(X)\n",
        "        self.P[:, :, 1::2] = torch.cos(X)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
        "        return self.dropout(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XJJJcAU14dz",
        "outputId": "477142e7-7d5b-48b8-f7ca-c14b9bded7db"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Test the PositionalEncoding class with a toy model for 4 dimensions. \n",
        "The  4th  dimension has the same frequency as the 5th but with different offset (i.e. phase)\n",
        "because one is produced by a sine function and the other is produced by a cosine function. \n",
        "The  6th  and  7th  dimensions have lower frequency.\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "pe = PositionalEncoding(20, 0)\n",
        "pe.eval()\n",
        "Y = pe(torch.zeros((1, 100, 20))).data.cpu().numpy()  # 1 example, 100 words with embedding dim of 20\n",
        "fig = plt.figure(figsize=(8, 4))\n",
        "ax = fig.add_subplot(111)\n",
        "for p in [4, 5, 6, 7]:\n",
        "    ax.plot(np.arange(100), Y[0, :, p].T, label=f'dim {p}')\n",
        "ax.legend()\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opO4tDz314d4"
      },
      "outputs": [],
      "source": [
        "# Embeddings class: sequences -> features\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab_size, max_position_embeddings, dropout=0):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
        "        self.position_embeddings = PositionalEncoding(num_hiddens=d_model, dropout=self.dropout,\n",
        "                                                      max_len=max_position_embeddings)\n",
        "\n",
        "        self.LayerNorm = nn.LayerNorm(d_model, eps=1e-12)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        seq_length = input_ids.size(1)\n",
        "        \n",
        "        # Get word embeddings for each input id\n",
        "        word_embeddings = self.word_embeddings(input_ids)                   # (bs, max_seq_length, dim)\n",
        "        \n",
        "        # Get position embeddings for the word embeddings and add them     \n",
        "        embeddings = self.position_embeddings(word_embeddings) # (bs, max_seq_length, dim)\n",
        "        \n",
        "        # Layer norm \n",
        "        embeddings = self.LayerNorm(embeddings)             # (bs, max_seq_length, dim)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe5G921X14d5"
      },
      "outputs": [],
      "source": [
        "# Transformer encoder\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, conv_hidden_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.dropout = dropout\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads, dropout=dropout)\n",
        "        self.cnn = CNN(d_model, conv_hidden_dim)\n",
        "\n",
        "        self.layernorm1 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "        self.layernorm2 = nn.LayerNorm(normalized_shape=d_model, eps=1e-6)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Multi-head attention \n",
        "        attn_output, _ = self.mha(x, x, x)  # (batch_size, input_seq_len, d_model)\n",
        "        \n",
        "        # Layer norm after adding the residual connection \n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "        \n",
        "        # Feed forward \n",
        "        cnn_output = self.cnn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        \n",
        "        # Second layer norm after adding residual connection \n",
        "        out2 = self.layernorm2(out1 + cnn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, ff_hidden_dim, input_vocab_size,\n",
        "               maximum_position_encoding, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = Embeddings(d_model, input_vocab_size,maximum_position_encoding, dropout)\n",
        "\n",
        "        self.enc_layers = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.enc_layers.append(EncoderLayer(d_model, num_heads, ff_hidden_dim, self.dropout))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x) # Transform to (batch_size, input_seq_length, d_model)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWOZR7oZ14d6"
      },
      "outputs": [],
      "source": [
        "# Transormer classifier for sentiment analysis\n",
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size, num_answers):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = TransformerEncoder(num_layers, d_model, num_heads, conv_hidden_dim, input_vocab_size,\n",
        "                                          maximum_position_encoding=10000)\n",
        "        self.dense = nn.Linear(d_model, num_answers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x, _ = torch.max(x, dim=1)\n",
        "        x = self.dense(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjh8L8vy14d7",
        "outputId": "f228c595-7dfd-4a73-83fe-f38668e2cc3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TransformerClassifier(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (embedding): Embeddings(\n",
              "      (word_embeddings): Embedding(50002, 32, padding_idx=1)\n",
              "      (position_embeddings): PositionalEncoding(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (LayerNorm): LayerNorm((32,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "    (enc_layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (mha): MultiHeadAttention(\n",
              "          (W_q): Linear(in_features=32, out_features=32, bias=False)\n",
              "          (W_k): Linear(in_features=32, out_features=32, bias=False)\n",
              "          (W_v): Linear(in_features=32, out_features=32, bias=False)\n",
              "          (W_h): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (cnn): CNN(\n",
              "          (k1convL1): Linear(in_features=32, out_features=128, bias=True)\n",
              "          (k1convL2): Linear(in_features=128, out_features=32, bias=True)\n",
              "          (activation): ReLU()\n",
              "        )\n",
              "        (layernorm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "        (layernorm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dense): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TransformerClassifier(num_layers=1, d_model=32, num_heads=2, \n",
        "                         conv_hidden_dim=128, input_vocab_size=50002, num_answers=2)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn9sVGAh14d9"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
        "    (ds_train, ds_valid, ds_test), batch_size=batch_size, sort_key=lambda x: len(x.text), repeat=False)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "epochs = 10\n",
        "t_total = len(train_loader) * epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ln5PQa414d9"
      },
      "outputs": [],
      "source": [
        "def evaluate(data_loader):\n",
        "    data_iterator = iter(data_loader)\n",
        "    nb_batches = len(data_loader)\n",
        "    model.eval()\n",
        "    acc = 0 \n",
        "    for batch in data_iterator:\n",
        "        x = batch.text.to(device)\n",
        "        y = batch.label.to(device)\n",
        "                \n",
        "        out = model(x)\n",
        "        acc += (out.argmax(1) == y).cpu().numpy().mean()\n",
        "\n",
        "    print(f\"eval accuracy: {acc / nb_batches}\")\n",
        "    \n",
        "    \n",
        "\n",
        "def train(train_loader, valid_loader):\n",
        "    for epoch in range(epochs):\n",
        "        train_iterator, valid_iterator = iter(train_loader), iter(valid_loader)\n",
        "        nb_batches_train = len(train_loader)\n",
        "        train_acc = 0\n",
        "        model.train()\n",
        "        losses = 0.0\n",
        "\n",
        "        for batch in train_iterator:\n",
        "            x = batch.text.to(device)\n",
        "            y = batch.label.to(device)\n",
        "            \n",
        "            out = model(x)\n",
        "\n",
        "            loss = f.cross_entropy(out, y)\n",
        "            \n",
        "            model.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "            losses += loss.item()\n",
        "\n",
        "            optimizer.step()\n",
        "                        \n",
        "            train_acc += (out.argmax(1) == y).cpu().numpy().mean()\n",
        "        \n",
        "        print(f\"epoch {epoch}: train loss: {losses / nb_batches_train}\")\n",
        "        print(f\"training accuracy: {train_acc / nb_batches_train}\")\n",
        "        print('evaluating on validation:')\n",
        "        evaluate(valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goOlrQ-_14d-",
        "outputId": "e02cfa8b-dc09-4e96-cbbd-dd095ace015f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss at epoch 0 is 0.6815725849433378\n",
            "Training accuracy: 0.5615980113636364\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.6268382352941176\n",
            "Training loss at epoch 1 is 0.6165380603210493\n",
            "Training accuracy: 0.6621182528409091\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.6940716911764706\n",
            "Training loss at epoch 2 is 0.5264402922581543\n",
            "Training accuracy: 0.7381285511363636\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.7510110294117647\n",
            "Training loss at epoch 3 is 0.45109065588225017\n",
            "Training accuracy: 0.7883558238636365\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.7962316176470587\n",
            "Training loss at epoch 4 is 0.39714851535179396\n",
            "Training accuracy: 0.8223277698863637\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.7951056985294118\n",
            "Training loss at epoch 5 is 0.34971896719864826\n",
            "Training accuracy: 0.8463831676136363\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8150735294117647\n",
            "Training loss at epoch 6 is 0.3135388213294474\n",
            "Training accuracy: 0.8648650568181818\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8344669117647058\n",
            "Training loss at epoch 7 is 0.2782035952603275\n",
            "Training accuracy: 0.8855930397727273\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.8379365808823529\n",
            "Training loss at epoch 8 is 0.25173457576469943\n",
            "Training accuracy: 0.8959215198863636\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.840234375\n",
            "Training loss at epoch 9 is 0.2241046568378806\n",
            "Training accuracy: 0.9111612215909091\n",
            "Evaluating on validation:\n",
            "Eval accuracy: 0.84140625\n"
          ]
        }
      ],
      "source": [
        "train(train_loader, valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu63x2LX14d_",
        "outputId": "75639381-22d9-45b0-87c5-fc8493a8ad1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval accuracy: 0.8221699617346938\n"
          ]
        }
      ],
      "source": [
        "evaluate(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXuHX1bw14eA"
      },
      "source": [
        "#### Transformer's Decoder Module\n",
        "---\n",
        "<img src=\"https://github.com/ynahum/ee046211-deep-learning/blob/main/assets/transformer_dec.png?raw=1\" style=\"height:300px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1nGxHJO14eA"
      },
      "source": [
        "* The Transformer decoder block looks similar to the Transformer encoder block. \n",
        "* However, besides the two sub-layers (the multi-head attention layer and the positional encoding network), the decoder Transformer block contains a third sub-layer, which applies multi-head attention on the output of the encoder stack.\n",
        "* **Cross-attention**: The cross attention follows the query, key, and value setup used for the self-attention blocks. However, the inputs are a little more complicated. \n",
        "    * The input to the decoder is a data point $y_i$, which is then passed through the self attention and add norm blocks, and finally ends up at the cross-attention block. \n",
        "    * This serves as the query for cross-attention, where the key and value pairs are the output $h^{Enc}$, where this output was calculated with all past inputs $x_1, ..., x_t$.\n",
        "* During training, the output for the $t$-query could observe all the previous key-value pairs. \n",
        "* It results in an different behavior from prediction. Thus, during *prediction* we can eliminate the unnecessary information by specifying the valid length to be $t$ for the $t^{th}$ query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM8EOGc914eB"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/cotton/64/000000/torch.png\" style=\"height:50px;display:inline\"> Native Transformer in PyTorch\n",
        "---\n",
        "* Transformer is implmented natively in PyTorch: `torch.nn.Transformer(d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6, num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1, activation: str = 'relu')`\n",
        "* <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\">Documentation</a>\n",
        "* <a href=\"https://github.com/pytorch/examples/blob/master/word_language_model/main.py\">Code example usage</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZ1YCwA214eB"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/plasticine/100/000000/teacher.png\" style=\"height:50px;display:inline\"> Teacher Forcing\n",
        "---\n",
        "* Teacher forcing is a strategy for training recurrent neural networks that uses model output from a prior time step as an input.\n",
        "* Teacher forcing works by using the actual or expected output from the training dataset at the current time step $y_t$ as input in the next time step $X_{t+1}$, rather than the output generated by the network.\n",
        "* This startegy allows for faster training, especially in RNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6OcBcZr14eC"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/emoji/96/000000/woman-lifting-weights.png\" style=\"height:50px;display:inline\"> Pretrained Models - BERT and GPT\n",
        "---\n",
        "* Large-scale pretrained models have gained popularity over the past years, as big companies can train very large models, which are then published for the public to use as-is or to use with fine-tuning for the users' custom datasets.\n",
        "* **Bidirectional Encoder Representations from Transformers (BERT), Google** - a Transformer-based machine learning technique for natural language processing (NLP) pre-training developed by Google. The idea is to mask certain words and then try to predict them. The original English-language BERT model comes with two pre-trained general types:\n",
        "    * (1) the $BERT_{BASE}$ model, a 12-layer, 768-hidden, 12-heads, 110M parameter neural network architecture.\n",
        "    * (2) the $BERT_{LARGE}$ model, a 24-layer, 1024-hidden, 16-heads, 340M parameter neural network architecture. \n",
        "    * Both of which were trained on the BooksCorpus dataset with 800M words, and a version of the English Wikipedia with 2,500M words.\n",
        "    * Extensions: RoBERTa (Facebook), DistillBERT (HuggingFace)\n",
        "* **Generative Pre-trained Transformer (GPT), OpenAI** - an autoregressive language model that uses deep learning to produce human-like text. GPT was trained with a causal language modeling (CLM) objective and is therefore powerful at predicting the next token in a sequence. The proposed method utilizes generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. Unlike BERT, GPT is a generative model, while BERT is an effective pretrained model for embeddings of words/sentences.\n",
        "    * GPT Demo - <a href=\"https://transformer.huggingface.co/doc/gpt\">Write With Transformer</a>\n",
        "* HuggingFace is a copmpany that is dedicated to publishing all of the available pretrained models and it works in PyTorch as well - <a href=\"https://github.com/huggingface/transformers\">HuggingFace Transformers</a>\n",
        "* <a href=\"https://pytorch.org/hub/huggingface_pytorch-transformers/\">Examples with PyTorch</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo7Uccu214eC"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/video-playlist.png\" style=\"height:50px;display:inline\"> Recommended Videos\n",
        "---\n",
        "#### <img src=\"https://img.icons8.com/cute-clipart/64/000000/warning-shield.png\" style=\"height:30px;display:inline\"> Warning!\n",
        "* These videos do not replace the lectures and tutorials.\n",
        "* Please use these to get a better understanding of the material, and not as an alternative to the written material.\n",
        "\n",
        "#### Video By Subject\n",
        "\n",
        "* Deep Learning for Natural Language Processing (NLP) -  <a href=\"https://youtu.be/6D4EWKJgNn0\"> Deep Learning for Natural Language Processing (NLP) </a>\n",
        "    * Attention and the Transformer <a href=\"https://www.youtube.com/watch?v=f01J0Dri-6k&feature=youtu.be\">Practicum: Attention and the Transformer</a>\n",
        "\n",
        "* Recurrent Neural Networks - <a href=\"https://www.youtube.com/watch?v=SEnXr6v2ifU\"> Recurrent Neural Networks | MIT 6.S191 </a>\n",
        "\n",
        "* LSTM & GRU - <a href=\"https://www.youtube.com/watch?v=8HyCNIVRbSU\"> Illustrated Guide to LSTM's and GRU's: A step by step explanation </a>\n",
        "\n",
        "* Transformers - <a href=\"https://www.youtube.com/watch?v=S27pHKBEp30\">LSTM is dead. Long Live Transformers! </a>\n",
        "* BERT - <a href=\"https://www.youtube.com/watch?v=OR0wfP2FD3c\">BERT Explained!</a>\n",
        "* GPT - <a href=\"https://www.youtube.com/watch?v=9ebPNEHRwXU\">GPT Explained!</a>\n",
        "    * GPT-3 - <a href=\"https://www.youtube.com/watch?v=_x9AwxfjxvE\">OpenAI GPT-3 - Good At Almost Everything!</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsKJd4Ma14eD"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
        "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
        "* <a href=\"https://d2l.ai/chapter_recurrent-neural-networks/index.html\">Dive Into Deep Learning - Recurrent Neural Networks</a>\n",
        "* <a href=\"https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-1/\">DS-GA 1008 - NYU CENTER FOR DATA SCIENCE - Deep Sequence Modeling</a>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "ee046211_tutorial_07_sequential_tasks_rnn.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}